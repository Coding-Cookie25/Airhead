{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":533474,"sourceType":"datasetVersion","datasetId":30764},{"sourceId":1377609,"sourceType":"datasetVersion","datasetId":630055}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n# Load sarcasm dataset\nsarcasm_path = \"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\"\n\nwith open(sarcasm_path, \"r\") as f:\n    sarcasm_data = [json.loads(line) for line in f]\n\nsarcasm_df = pd.DataFrame(sarcasm_data)\n\nprint(sarcasm_df.head())\nprint(sarcasm_df[\"is_sarcastic\"].value_counts())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T07:50:36.739926Z","iopub.execute_input":"2025-08-31T07:50:36.740279Z","iopub.status.idle":"2025-08-31T07:50:36.885549Z","shell.execute_reply.started":"2025-08-31T07:50:36.740255Z","shell.execute_reply":"2025-08-31T07:50:36.884572Z"}},"outputs":[{"name":"stdout","text":"                                        article_link  \\\n0  https://www.huffingtonpost.com/entry/versace-b...   \n1  https://www.huffingtonpost.com/entry/roseanne-...   \n2  https://local.theonion.com/mom-starting-to-fea...   \n3  https://politics.theonion.com/boehner-just-wan...   \n4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n\n                                            headline  is_sarcastic  \n0  former versace store clerk sues over secret 'b...             0  \n1  the 'roseanne' revival catches up to our thorn...             0  \n2  mom starting to fear son's web series closest ...             1  \n3  boehner just wants wife to listen, not come up...             1  \n4  j.k. rowling wishes snape happy birthday in th...             0  \nis_sarcastic\n0    14985\n1    11724\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\nair_path = \"/kaggle/input/air-quality-data-in-india\"\nprint(os.listdir(air_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:35:51.529822Z","iopub.execute_input":"2025-08-31T08:35:51.530164Z","iopub.status.idle":"2025-08-31T08:35:51.536983Z","shell.execute_reply.started":"2025-08-31T08:35:51.530133Z","shell.execute_reply":"2025-08-31T08:35:51.536222Z"}},"outputs":[{"name":"stdout","text":"['stations.csv', 'station_hour.csv', 'city_day.csv', 'city_hour.csv', 'station_day.csv']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\n\nair_file = \"/kaggle/input/air-quality-data-in-india/city_day.csv\"\nair_df = pd.read_csv(air_file)\n\nprint(air_df.head())\nprint(air_df.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T08:36:15.401633Z","iopub.execute_input":"2025-08-31T08:36:15.401921Z","iopub.status.idle":"2025-08-31T08:36:15.537897Z","shell.execute_reply.started":"2025-08-31T08:36:15.401900Z","shell.execute_reply":"2025-08-31T08:36:15.537079Z"}},"outputs":[{"name":"stdout","text":"        City        Date  PM2.5  PM10     NO    NO2    NOx  NH3     CO    SO2  \\\n0  Ahmedabad  2015-01-01    NaN   NaN   0.92  18.22  17.15  NaN   0.92  27.64   \n1  Ahmedabad  2015-01-02    NaN   NaN   0.97  15.69  16.46  NaN   0.97  24.55   \n2  Ahmedabad  2015-01-03    NaN   NaN  17.40  19.30  29.70  NaN  17.40  29.07   \n3  Ahmedabad  2015-01-04    NaN   NaN   1.70  18.48  17.97  NaN   1.70  18.59   \n4  Ahmedabad  2015-01-05    NaN   NaN  22.10  21.42  37.76  NaN  22.10  39.33   \n\n       O3  Benzene  Toluene  Xylene  AQI AQI_Bucket  \n0  133.36     0.00     0.02    0.00  NaN        NaN  \n1   34.06     3.68     5.50    3.77  NaN        NaN  \n2   30.70     6.80    16.40    2.25  NaN        NaN  \n3   36.08     4.43    10.14    1.00  NaN        NaN  \n4   39.31     7.01    18.89    2.78  NaN        NaN  \nIndex(['City', 'Date', 'PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2',\n       'O3', 'Benzene', 'Toluene', 'Xylene', 'AQI', 'AQI_Bucket'],\n      dtype='object')\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Step 1: Import libraries\nimport pandas as pd\n\n# Step 2: Load the News Headlines Sarcasm Dataset\n# Make sure the dataset CSV is uploaded to Kaggle under /kaggle/input/news-headlines-dataset-for-sarcasm-detection/\nfile_path = \"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\"\n\n# Dataset is in JSON format, one headline per line\ndf = pd.read_json(file_path, lines=True)\n\n# Step 3: Peek at the dataset\nprint(\"Dataset shape:\", df.shape)\nprint(\"Columns:\", df.columns)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:25:16.983179Z","iopub.execute_input":"2025-08-31T12:25:16.983526Z","iopub.status.idle":"2025-08-31T12:25:19.407658Z","shell.execute_reply.started":"2025-08-31T12:25:16.983491Z","shell.execute_reply":"2025-08-31T12:25:19.406769Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (26709, 3)\nColumns: Index(['article_link', 'headline', 'is_sarcastic'], dtype='object')\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                        article_link  \\\n0  https://www.huffingtonpost.com/entry/versace-b...   \n1  https://www.huffingtonpost.com/entry/roseanne-...   \n2  https://local.theonion.com/mom-starting-to-fea...   \n3  https://politics.theonion.com/boehner-just-wan...   \n4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n\n                                            headline  is_sarcastic  \n0  former versace store clerk sues over secret 'b...             0  \n1  the 'roseanne' revival catches up to our thorn...             0  \n2  mom starting to fear son's web series closest ...             1  \n3  boehner just wants wife to listen, not come up...             1  \n4  j.k. rowling wishes snape happy birthday in th...             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_link</th>\n      <th>headline</th>\n      <th>is_sarcastic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n      <td>former versace store clerk sues over secret 'b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n      <td>the 'roseanne' revival catches up to our thorn...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n      <td>mom starting to fear son's web series closest ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://politics.theonion.com/boehner-just-wan...</td>\n      <td>boehner just wants wife to listen, not come up...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n      <td>j.k. rowling wishes snape happy birthday in th...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import random\n\n# Step 2: Define AQI ranges and sarcastic remark templates\naqi_ranges = {\n    \"0-50\": [\n        \"Wow, fresh air… almost tastes like lungs’ vacation.\",\n        \"AQI is low, lungs are on holiday, enjoy the free oxygen!\"\n    ],\n    \"51-150\": [\n        \"Mild poison is normal, right? Just a whiff of smog.\",\n        \"Air is slightly toxic today, but who cares?\"\n    ],\n    \"151-200\": [\n        \"Breathing this is basically instant smoker vibes.\",\n        \"Air so polluted, even my mask is giving up.\"\n    ],\n    \"201-300\": [\n        \"Don’t need coffee, just inhale the morning smog.\",\n        \"AQI is high, who needs clean air anyway?\"\n    ],\n    \"301+\": [\n        \"Air so toxic, even zombies would think twice.\",\n        \"Step outside, become one with the smog apocalypse.\"\n    ]\n}\n\n# Step 3: Generate synthetic dataset\nsynthetic_data = []\n\nfor i in range(300):  # generate 300 samples\n    aqi_level = random.randint(0, 350)\n    \n    if aqi_level <= 50:\n        remark = random.choice(aqi_ranges[\"0-50\"])\n    elif aqi_level <= 150:\n        remark = random.choice(aqi_ranges[\"51-150\"])\n    elif aqi_level <= 200:\n        remark = random.choice(aqi_ranges[\"151-200\"])\n    elif aqi_level <= 300:\n        remark = random.choice(aqi_ranges[\"201-300\"])\n    else:\n        remark = random.choice(aqi_ranges[\"301+\"])\n    \n    synthetic_data.append({\n        \"AQI\": aqi_level,\n        \"remark\": remark\n    })\n\n# Step 4: Convert to DataFrame\nsynthetic_df = pd.DataFrame(synthetic_data)\n\n# Step 5: Save CSV (optional)\nsynthetic_df.to_csv(\"/kaggle/working/synthetic_aqi_sarcasm.csv\", index=False)\n\nsynthetic_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:27:46.518934Z","iopub.execute_input":"2025-08-31T12:27:46.519306Z","iopub.status.idle":"2025-08-31T12:27:46.541011Z","shell.execute_reply.started":"2025-08-31T12:27:46.519283Z","shell.execute_reply":"2025-08-31T12:27:46.539994Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   AQI                                             remark\n0  138  Mild poison is normal, right? Just a whiff of ...\n1  219           AQI is high, who needs clean air anyway?\n2  260           AQI is high, who needs clean air anyway?\n3  258   Don’t need coffee, just inhale the morning smog.\n4   90  Mild poison is normal, right? Just a whiff of ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>remark</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>138</td>\n      <td>Mild poison is normal, right? Just a whiff of ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>219</td>\n      <td>AQI is high, who needs clean air anyway?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>260</td>\n      <td>AQI is high, who needs clean air anyway?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>258</td>\n      <td>Don’t need coffee, just inhale the morning smog.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>90</td>\n      <td>Mild poison is normal, right? Just a whiff of ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import random\nimport pandas as pd\n\n# Step 1: Define AQI ranges\naqi_ranges = {\n    \"0-50\": \"good\",\n    \"51-150\": \"moderate\",\n    \"151-200\": \"unhealthy\",\n    \"201-300\": \"very unhealthy\",\n    \"301+\": \"hazardous\"\n}\n\n# Step 2: Define sentence fragments for dynamic remarks\nstarts = [\n    \"Breathe in…\", \"Step outside…\", \"Air today is\", \"Good luck with\",\n    \"Lungs, prepare for\", \"Congrats on\"\n]\n\nmiddles = {\n    \"good\": [\"fresh air\", \"almost perfect oxygen\", \"lungs’ vacation\", \"clean breeze\"],\n    \"moderate\": [\"slightly toxic air\", \"mild poison\", \"casual smog\", \"lung seasoning\"],\n    \"unhealthy\": [\"polluted haze\", \"instant smoker vibes\", \"smog overload\", \"toxic clouds\"],\n    \"very unhealthy\": [\"lung torture session\", \"apocalypse air\", \"extreme smog\", \"dangerous fumes\"],\n    \"hazardous\": [\"air so toxic even zombies complain\", \"death soup\", \"lethal smog\", \"lungs filing complaints\"]\n}\n\nends = [\n    \"enjoy it!\", \"if you dare.\", \"your lungs will thank you… maybe.\", \n    \"instant regret guaranteed.\", \"survival mode activated.\", \"just another day outside.\"\n]\n\n# Step 3: Generate synthetic dataset\nsynthetic_data = []\n\nfor i in range(300):  # generate 300 samples\n    aqi_level = random.randint(0, 350)\n    \n    # Determine AQI category\n    if aqi_level <= 50:\n        category = \"good\"\n    elif aqi_level <= 150:\n        category = \"moderate\"\n    elif aqi_level <= 200:\n        category = \"unhealthy\"\n    elif aqi_level <= 300:\n        category = \"very unhealthy\"\n    else:\n        category = \"hazardous\"\n    \n    # Build dynamic remark\n    remark = f\"{random.choice(starts)} {random.choice(middles[category])}, {random.choice(ends)}\"\n    \n    synthetic_data.append({\n        \"AQI\": aqi_level,\n        \"remark\": remark\n    })\n\n# Step 4: Convert to DataFrame\nsynthetic_df = pd.DataFrame(synthetic_data)\n\n# Step 5: Save CSV (optional)\nsynthetic_df.to_csv(\"/kaggle/working/synthetic_aqi_sarcasm_unique.csv\", index=False)\n\nsynthetic_df.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:29:15.617540Z","iopub.execute_input":"2025-08-31T12:29:15.617903Z","iopub.status.idle":"2025-08-31T12:29:15.637843Z","shell.execute_reply.started":"2025-08-31T12:29:15.617881Z","shell.execute_reply":"2025-08-31T12:29:15.636973Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   AQI                                             remark\n0    9         Air today is lungs’ vacation, if you dare.\n1  344  Good luck with air so toxic even zombies compl...\n2  108  Step outside… slightly toxic air, your lungs w...\n3    4  Congrats on clean breeze, survival mode activa...\n4   35             Breathe in… lungs’ vacation, enjoy it!\n5   92  Breathe in… mild poison, survival mode activated.\n6    9  Good luck with lungs’ vacation, your lungs wil...\n7   49    Good luck with almost perfect oxygen, enjoy it!\n8  158  Air today is instant smoker vibes, survival mo...\n9  321  Lungs, prepare for lethal smog, your lungs wil...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AQI</th>\n      <th>remark</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9</td>\n      <td>Air today is lungs’ vacation, if you dare.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>344</td>\n      <td>Good luck with air so toxic even zombies compl...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>108</td>\n      <td>Step outside… slightly toxic air, your lungs w...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Congrats on clean breeze, survival mode activa...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>Breathe in… lungs’ vacation, enjoy it!</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>92</td>\n      <td>Breathe in… mild poison, survival mode activated.</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>9</td>\n      <td>Good luck with lungs’ vacation, your lungs wil...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>49</td>\n      <td>Good luck with almost perfect oxygen, enjoy it!</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>158</td>\n      <td>Air today is instant smoker vibes, survival mo...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>321</td>\n      <td>Lungs, prepare for lethal smog, your lungs wil...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"!pip install transformers datasets\n\nimport pandas as pd\nimport torch\nfrom datasets import Dataset, concatenate_datasets\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:30:14.700211Z","iopub.execute_input":"2025-08-31T12:30:14.700587Z","iopub.status.idle":"2025-08-31T12:30:58.257958Z","shell.execute_reply.started":"2025-08-31T12:30:14.700562Z","shell.execute_reply":"2025-08-31T12:30:58.256883Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\n","output_type":"stream"},{"name":"stderr","text":"2025-08-31 12:30:41.861177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756643442.072236      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756643442.137158      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load base sarcasm dataset (headlines)\nsarcasm_df = pd.read_json(\"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\", lines=True)\nsarcasm_df = sarcasm_df[sarcasm_df['is_sarcastic']==1]  # only sarcastic examples\nsarcasm_texts = sarcasm_df['headline'].tolist()\n\n# Load synthetic AQI sarcasm dataset\naqi_df = pd.read_csv(\"/kaggle/working/synthetic_aqi_sarcasm_unique.csv\")\naqi_texts = aqi_df['remark'].tolist()\n\n# Combine both datasets\nall_texts = sarcasm_texts + aqi_texts\ndataset = Dataset.from_dict({\"text\": all_texts})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:31:20.934467Z","iopub.execute_input":"2025-08-31T12:31:20.935181Z","iopub.status.idle":"2025-08-31T12:31:21.048905Z","shell.execute_reply.started":"2025-08-31T12:31:20.935150Z","shell.execute_reply":"2025-08-31T12:31:21.048068Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Show first 10 examples\nprint(\"Total samples:\", len(dataset))\nprint(\"First 10 examples:\")\nfor i, item in enumerate(dataset['text'][:10]):\n    print(f\"{i+1}: {item}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:32:45.702349Z","iopub.execute_input":"2025-08-31T12:32:45.703317Z","iopub.status.idle":"2025-08-31T12:32:45.727435Z","shell.execute_reply.started":"2025-08-31T12:32:45.703283Z","shell.execute_reply":"2025-08-31T12:32:45.726423Z"}},"outputs":[{"name":"stdout","text":"Total samples: 12024\nFirst 10 examples:\n1: mom starting to fear son's web series closest thing she will have to grandchild\n2: boehner just wants wife to listen, not come up with alternative debt-reduction ideas\n3: top snake handler leaves sinking huckabee campaign\n4: nuclear bomb detonates during rehearsal for 'spider-man' musical\n5: cosby lawyer asks why accusers didn't come forward to be smeared by legal team years ago\n6: stock analysts confused, frightened by boar market\n7: courtroom sketch artist has clear manga influences\n8: trump assures nation that decision for syrian airstrikes came after carefully considering all his passing whims\n9: ex-con back behind bar\n10: after careful consideration, bush recommends oil drilling\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\ntokenizer.pad_token = tokenizer.eos_token  # GPT-2 does not have a pad token\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, max_length=64)\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:34:27.436638Z","iopub.execute_input":"2025-08-31T12:34:27.437573Z","iopub.status.idle":"2025-08-31T12:34:32.944724Z","shell.execute_reply.started":"2025-08-31T12:34:27.437545Z","shell.execute_reply":"2025-08-31T12:34:32.943574Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6640b00ee2aa4565b09b8ea46c970aa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c2336c66c664c19961b9038e3aab566"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b44f5c3c6f14c6bbc6a350f97c63246"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb6adcb196f44884a00a9ad9d4efe045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df4f4a401b7846609b5ad4a11da4a4a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12024 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd1ac1d78db44dfa92f772562167dfe8"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,  # GPT-2 is causal LM\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:35:04.490525Z","iopub.execute_input":"2025-08-31T12:35:04.490847Z","iopub.status.idle":"2025-08-31T12:35:04.495585Z","shell.execute_reply.started":"2025-08-31T12:35:04.490824Z","shell.execute_reply":"2025-08-31T12:35:04.494446Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\nmodel.resize_token_embeddings(len(tokenizer))  # resize if we add tokens\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:35:14.905580Z","iopub.execute_input":"2025-08-31T12:35:14.905893Z","iopub.status.idle":"2025-08-31T12:35:17.713400Z","shell.execute_reply.started":"2025-08-31T12:35:14.905875Z","shell.execute_reply":"2025-08-31T12:35:17.712510Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b5657a85a704082b0ad91838c491579"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c2de07ad243479e945db4bfec4d4ba7"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Embedding(50257, 768)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/kaggle/working/gpt2-aqi-sarcasm\",\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    save_steps=500,\n    save_total_limit=2,\n    prediction_loss_only=True,\n    logging_steps=100,\n    run_name=\"AQI_sarcasm_training\",\n    fp16=True,\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:37:50.427902Z","iopub.execute_input":"2025-08-31T12:37:50.428307Z","iopub.status.idle":"2025-08-31T12:37:50.435276Z","shell.execute_reply.started":"2025-08-31T12:37:50.428281Z","shell.execute_reply":"2025-08-31T12:37:50.434235Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    data_collator=data_collator\n)\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T12:37:53.222735Z","iopub.execute_input":"2025-08-31T12:37:53.223088Z","iopub.status.idle":"2025-08-31T13:07:48.109990Z","shell.execute_reply.started":"2025-08-31T12:37:53.223056Z","shell.execute_reply":"2025-08-31T13:07:48.106571Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1532' max='9018' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1532/9018 29:48 < 2:25:51, 0.86 it/s, Epoch 0.51/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>5.614700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>5.444700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>5.382200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.240900</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>5.318600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.175700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>5.186100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>5.170600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>5.083200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>5.055700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>5.022700</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>4.990900</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>5.089800</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>4.985400</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>4.923000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1560042111.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata_collator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_collator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2604\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_pre_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2606\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2608\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerate_step_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDistributedType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXLA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_xla_gradients_synced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    876\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"prompt = \"AQI is 180:\"\ninputs = tokenizer.encode(prompt, return_tensors=\"pt\")\noutputs = model.generate(\n    inputs, \n    max_length=50, \n    do_sample=True, \n    top_k=50, \n    top_p=0.95, \n    temperature=0.8\n)\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n","metadata":{"trusted":true},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"AQI is 180:30 left to announce plans to deploy nation's newest air force deploys in three-four-hour span of time to protect and/or enhance nation's air force's air combat capabilities by developing new weapons system that can\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/kaggle/working/gpt2-aqi-sarcasm-quick\",\n    overwrite_output_dir=True,\n    num_train_epochs=0.5,   # half an epoch\n    per_device_train_batch_size=4,\n    save_steps=500,\n    save_total_limit=2,\n    prediction_loss_only=True,\n    logging_steps=100,\n    run_name=\"AQI_sarcasm_quick\",\n    fp16=True,\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:12:29.229145Z","iopub.execute_input":"2025-08-31T13:12:29.229656Z","iopub.status.idle":"2025-08-31T13:12:29.241745Z","shell.execute_reply.started":"2025-08-31T13:12:29.229625Z","shell.execute_reply":"2025-08-31T13:12:29.240697Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    data_collator=data_collator\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T13:12:37.177624Z","iopub.execute_input":"2025-08-31T13:12:37.177925Z","iopub.status.idle":"2025-08-31T13:43:26.931877Z","shell.execute_reply.started":"2025-08-31T13:12:37.177905Z","shell.execute_reply":"2025-08-31T13:43:26.930556Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1503' max='1503' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1503/1503 30:46, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>3.972400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>3.984900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>3.894600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>3.784300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>3.889500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.829200</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>3.919700</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.912200</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>3.855200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.864400</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>3.867100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>3.896100</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>4.013700</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>3.936300</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>3.954400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1503, training_loss=3.904779288265916, metrics={'train_runtime': 1848.8783, 'train_samples_per_second': 3.252, 'train_steps_per_second': 0.813, 'total_flos': 26946227404800.0, 'train_loss': 3.904779288265916, 'epoch': 0.5})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"import os\n\n# Check if the model directory exists\nmodel_dir = \"/kaggle/working/gpt2-aqi-sarcasm\"  # change if your output_dir is different\nif os.path.exists(model_dir):\n    print(\"Model directory exists! ✅\")\n    # List contents\n    print(\"Contents of model directory:\")\n    print(os.listdir(model_dir))\nelse:\n    print(\"Model directory not found. 😢\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T14:24:49.268854Z","iopub.execute_input":"2025-08-31T14:24:49.270211Z","iopub.status.idle":"2025-08-31T14:24:49.281806Z","shell.execute_reply.started":"2025-08-31T14:24:49.270150Z","shell.execute_reply":"2025-08-31T14:24:49.280538Z"}},"outputs":[{"name":"stdout","text":"Model directory exists! ✅\nContents of model directory:\n['runs', 'checkpoint-1500', 'checkpoint-1000']\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import shutil\n\n# Path to your model directory\nmodel_dir = \"/kaggle/working/gpt2-aqi-sarcasm\"\n\n# Path for the zip file\nzip_path = \"/kaggle/working/gpt2-aqi-sarcasm.zip\"\n\n# Zip the folder\nshutil.make_archive(base_name=zip_path.replace('.zip',''), format='zip', root_dir=model_dir)\n\nprint(f\"Model zipped successfully! You can download it here: {zip_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T14:36:21.519459Z","iopub.execute_input":"2025-08-31T14:36:21.519992Z","iopub.status.idle":"2025-08-31T14:38:22.495722Z","shell.execute_reply.started":"2025-08-31T14:36:21.519965Z","shell.execute_reply":"2025-08-31T14:38:22.494526Z"}},"outputs":[{"name":"stdout","text":"Model zipped successfully! You can download it here: /kaggle/working/gpt2-aqi-sarcasm.zip\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Path to your zip file\nzip_path = \"/kaggle/working/gpt2-aqi-sarcasm.zip\"\n\n# Create a clickable download link\nFileLink(zip_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-31T14:38:57.843030Z","iopub.execute_input":"2025-08-31T14:38:57.843361Z","iopub.status.idle":"2025-08-31T14:38:57.852893Z","shell.execute_reply.started":"2025-08-31T14:38:57.843340Z","shell.execute_reply":"2025-08-31T14:38:57.852046Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/gpt2-aqi-sarcasm.zip","text/html":"<a href='/kaggle/working/gpt2-aqi-sarcasm.zip' target='_blank'>/kaggle/working/gpt2-aqi-sarcasm.zip</a><br>"},"metadata":{}}],"execution_count":28}]}